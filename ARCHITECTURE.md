# Architecture â€” ServiceUp Insights

## Overview

ServiceUp Insights is a standalone TypeScript/Node.js microservice that:
1. Ingests shop invoice PDFs via Gemini LLM into a structured PostgreSQL database
2. Computes fleet analytics metrics and cross-fleet benchmarks
3. Generates AI-powered insights (LLM-as-analyst + LLM-as-judge pipeline)
4. Serves the insights as self-contained HTML widgets embeddable in sa_portal via `<iframe>`

**Stack:** Node 22 Â· TypeScript 5 Â· Express Â· Prisma ORM Â· PostgreSQL 16 + pgvector Â· Gemini 2.5 Flash Â· LangChain Â· Firebase Admin Â· node-cron

---

## System Diagram

```
sa_portal (Next.js)
  â”‚
  â”‚  <iframe src="https://insights.serviceup.com/embed/dashboard?token=...">
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  serviceup-insights (port 4050)          â”‚
â”‚                                                         â”‚
â”‚  /embed/dashboard     â—„â”€â”€ JWT embed token auth          â”‚
â”‚  /embed/widget/:type  â—„â”€â”€ (fleetId baked into token)    â”‚
â”‚                                                         â”‚
â”‚  /api/v1/widgets      â—„â”€â”€ API key auth (x-api-key)      â”‚
â”‚  /api/v1/metrics      â—„â”€â”€ (for sa_portal backend)       â”‚
â”‚  /api/v1/embed-token  â—„â”€â”€ issues short-lived JWTs       â”‚
â”‚  /api/v1/health                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   PostgreSQL 16   â”‚     â”‚  Gemini 2.5 Flashâ”‚
    â”‚   + pgvector      â”‚     â”‚  (LLM + embeds) â”‚
    â”‚   port 5433       â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–²
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     Nightly Pipeline (cron)   â”‚
    â”‚     11:00 PM UTC              â”‚
    â”‚                              â”‚
    â”‚  1. Fetch new invoices        â”‚
    â”‚     (BigQuery via ADC)        â”‚
    â”‚  2. Download PDFs             â”‚
    â”‚     (Firebase Storage)        â”‚
    â”‚  3. Parse with Gemini LLM     â”‚
    â”‚  4. Embed for pgvector        â”‚
    â”‚  5. Generate insights         â”‚
    â”‚  6. Cache in insight_cache    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Layer Breakdown

### 1. Ingestion (`src/ingestion/`)

| File | Responsibility |
|------|----------------|
| `mainDbClient.ts` | BigQuery ADC client; fetches `service_requests` rows joined with shops/vehicles/fleets |
| `pdfFetcher.ts` | Downloads PDFs from Firebase Storage URLs or plain HTTP; 30s timeout |
| `schema.ts` | Zod schema defining the LLM output shape (invoices, services, line items) |
| `systemPrompt.ts` | Gemini system prompt for PDF parsing; includes CCC/collision format guidance |
| `pdfParser.ts` | Gemini Flash parse with Pro fallback when confidence < 0.6; manual Zod default normalization |
| `normalizer.ts` | Maps parsed LLM result â†’ Prisma upsert (ParsedInvoice + services + line items); date fallback from extras |
| `embedder.ts` | gemini-embedding-001 â†’ `$executeRaw` INSERT into `invoice_embeddings` (3072-dim vector) |
| `batchRunner.ts` | Sequential processing with 1s LLM rate-limit delay; `processPendingInvoices()` |

**PDF parsing flow:**
```
PDF URL â†’ base64 â†’ Gemini Flash â†’ Zod parse â†’ normalize defaults â†’ DB upsert â†’ embed
                          â†“ (confidence < 0.6)
                    Gemini Pro retry
```

**Important:** LangChain's `withStructuredOutput` does not apply Zod `.default()` values.
The result is manually normalized in `pdfParser.ts` after every `invoke()`.

**CCC/collision estimates:** Multi-page collision estimates often lack standard date fields.
`normalizer.ts` falls back to extras fields (`vehicle_out_date`, `printed_date`, etc.) for invoice_date.
Invoices that still have no extractable date get `invoice_date = NULL` â€” metrics queries include
`OR invoice_date IS NULL` so they are not silently excluded from fleet analytics.

---

### 2. Metrics (`src/metrics/metrics.ts`)

All analytics queries in one file. Each function takes `(fleetId, since)` and returns
a typed array via Prisma `$queryRaw`. Aggregate queries use `(invoice_date >= since OR invoice_date IS NULL)`
so undated invoices (e.g. collision estimates with no extractable date) are included.

**Spend:** `getTotalSpend`, `getSpendByShop`, `getMonthlySpend`, `getSpendVelocity`
**Labor:** `getAvgLaborRateByShop`, `getLaborHoursByShop`, `getLaborRateBenchmark`
**Parts:** `getTopReplacedParts`, `getPartPriceTrend`, `getPartCostBenchmark`, `getPartsQualityMix`
**Anomalies:** `getAnomalies` (items > 2Ïƒ above fleet mean, requires â‰¥ 3 occurrences)
**Vehicles:** `getVehicleRepairFrequency`, `getVehicleMultipleVisits`, `getShopTurnaround`
**Benchmarks:** `getFleetPercentiles` (window functions across all fleets)
**Summary:** `getFleetSummary`, `getCostBreakdown`

---

### 3. Intelligence (`src/intelligence/`)

| File | Responsibility |
|------|----------------|
| `llmAnalyzer.ts` | Full insight generation pipeline (metrics â†’ vector â†’ benchmarks â†’ NHTSA â†’ LLM â†’ judge â†’ cache) |
| `insightPrompts.ts` | Prompt builder (domain context, insight type catalog, detail_json format examples) and `JUDGE_SYSTEM_PROMPT` |
| `insightJudge.ts` | LLM-as-judge: evaluates N candidates, keeps those passing 5 quality criteria |
| `benchmarks.ts` | Aggregates `getFleetPercentiles` + `getLaborRateBenchmark` + top part benchmarks |
| `vectorRetriever.ts` | Semantic search via pgvector cosine similarity |
| `nhtsaRecalls.ts` | NHTSA public API; 7-day in-process cache per make/model/year; max 5 parallel requests |

**Insight generation pipeline:**
```
1. Parallel metrics queries (12 functions)
2. pgvector semantic search (top-5 similar invoice chunks)
3. Cross-fleet benchmarks (percentile rank, labor rate, part costs)
4. NHTSA recall check (per VIN, cached 7 days)
5. Gemini generates â‰¤15 insight candidates (JSON array)
6. Judge LLM filters by: non-obvious, actionable, â‰¥3 data points, non-redundant, >$100 impact
7. Upsert survivors into insight_cache (48h TTL, keyed by fleet:type:period:date)
```

**Supported insight types:**
`recall_alert`, `repeat_repair`, `vehicle_risk`, `vehicle_health`, `concentration_risk`,
`anomaly`, `cost_breakdown`, `top_parts`, `parts_trend`, `parts_quality`, `spend_spike`,
`labor_rates`, `turnaround_time`, `shop_recommendation`, `fleet_benchmark`, `part_benchmark`,
`seasonal`, `narrative`

---

### 4. Embed Layer (`src/embed/`)

Self-contained HTML pages served as iframes. Each page is a complete HTML document with
inline CSS and Chart.js loaded from CDN. No external runtime dependencies.

| Widget Type | Template | Use case |
|-------------|----------|----------|
| `chart_line` / `chart_bar` / `chart_pie` / `chart_area` | `chartWidget.ts` | Spend trends, top parts |
| `stat_card` | `statCard.ts` | Single KPI with delta and secondary stats |
| `table` / `comparison_table` | `tableWidget.ts` | Shop comparisons, part costs with diff pills |
| `narrative` | `narrativeWidget.ts` | Bullet-point insights with data chips |
| `alert` | `alertWidget.ts` | NHTSA recalls, anomalies, repeat repairs |

Dashboard sections (rendered by `dashboardGrid.ts`):
- `ğŸš¨ Safety & Alerts` â€” recalls, repeat repairs, anomalies
- `ğŸš— Vehicle Intelligence` â€” vehicle risk, health, concentration risk
- `ğŸ“Š Cost Analysis` â€” cost breakdown, top parts, parts quality, seasonal
- `ğŸª Shops & Vendors` â€” turnaround, shop recommendations, benchmarks
- `ğŸ“ Summary` â€” narrative insights

**Auth:** JWT embed tokens issued by `POST /api/v1/embed-token` (API key required).
Token payload contains `{ fleetId, iat, exp }`. Verified by `embedAuthMiddleware`.
Token TTL: 300â€“86400s (clamped server-side). `fleetId` in query string must match token claim.

**XSS protection:** All user-controlled strings go through `escapeHtml()`. Chart data is
serialized through `jsonEmbed()` which escapes `<`, `>`, `&` to Unicode escapes.

---

### 5. API Layer (`src/api/`)

```
GET  /api/v1/health               # liveness check â€” no auth
GET  /api/v1/widgets?fleetId=X    # JSON array of cached insights
POST /api/v1/widgets/generate     # fire-and-forget insight generation
GET  /api/v1/metrics?fleetId=X    # raw metrics JSON
POST /api/v1/embed-token          # { fleetId, ttl } â†’ { token }
```

Auth: `x-api-key` header checked against `API_KEY` env var.
If `API_KEY` is unset, all routes are open (warns to logger on first request).

---

## Database Schema

```
parsed_invoices          Core invoice row (requestId unique + pdfUrl)
  â”œâ”€â”€ parsed_invoice_services    Service lines (name, complaint, cause, correction)
  â”‚     â””â”€â”€ parsed_invoice_line_items   Parts/labor/sublet line items
  â””â”€â”€ invoice_embeddings         3072-dim pgvector embeddings

insight_cache            Pre-computed insights (48h TTL, upserted by insightKey)
pipeline_state           Job checkpoint (lastSuccessAt, lastRunAt per pipeline name)
```

**pgvector:** `invoice_embeddings.embedding` is `vector(3072)` using `gemini-embedding-001`.
No HNSW index currently (pgvector HNSW max is 2000 dims for `vector`).
For production scale, use `halfvec(3072)` + `halfvec_cosine_ops` (pgvector â‰¥ 0.7.0).
All operations via `$queryRaw` / `$executeRaw` â€” Prisma uses `Unsupported("vector(3072)")`.

---

## Authentication Model

| Surface | Mechanism | Notes |
|---------|-----------|-------|
| `/api/v1/*` | `x-api-key` header | Shared secret, sa_portal backend â†’ insights |
| `/embed/*` | JWT query param `?token=` | Short-lived, fleetId-scoped, issued by API |
| Internal jobs | None | Run in-process, no network auth |

---

## Environment Variables

| Variable | Required | Default | Notes |
|----------|----------|---------|-------|
| `DATABASE_URL` | âœ… | â€” | Must use port 5433 locally |
| `GEMINI_API_KEY` | âœ… | â€” | From `serviceupaistudio` GCP project |
| `EMBED_SECRET` | âœ… | placeholder | JWT signing secret â€” **change in prod** |
| `API_KEY` | âœ… | â€” | Unset = open (logs warning) |
| `SERVICE_ACCOUNT_JSON_BASE64` | â€” | â€” | Firebase service account (base64 JSON). Not needed locally if using ADC |
| `STORAGE_BUCKET` | â€” | serviceupios.appspot.com | |
| `PORT` | â€” | 4050 | |
| `INSIGHTS_BATCH_SIZE` | â€” | 10 | PDFs processed per batch |

**Firebase credential resolution order** (first match wins):
1. `SERVICE_ACCOUNT_JSON_BASE64` â€” base64-encoded JSON (Doppler/prod convention)
2. `FIREBASE_SERVICE_ACCOUNT_KEY` â€” raw inline JSON
3. `FIREBASE_SERVICE_ACCOUNT_KEY_PATH` â€” path to local JSON file
4. Application Default Credentials â€” `gcloud auth application-default login` (local dev) or workload identity (Cloud Run)

**BigQuery:** Uses Application Default Credentials directly (no separate env var needed).
Run `gcloud auth application-default login` once for local dev.

---

## Local Development

### First-time setup

```bash
# 1. Authenticate with GCP (gives Firebase Storage + BigQuery access via ADC)
gcloud auth application-default login

# 2. Start local Postgres on port 5433
docker compose up postgres -d

# 3. Create .env with minimum required vars
echo "DATABASE_URL=postgresql://insights:insights@localhost:5433/serviceup_insights" > .env
echo "GEMINI_API_KEY=<your key from serviceupaistudio>" >> .env

# 4. Run migrations and start
npm run db:migrate:dev
npm run dev
# â†’ http://localhost:4050

# 5. Smoke test
curl localhost:4050/api/v1/health
```

**Or with Doppler** (once `serviceup-insights/dev` config is created):
```bash
doppler run -- npm run dev
```

### What does and doesn't auto-run

**The server does NOT process PDFs on startup.** The nightly cron runs at 11pm UTC only.

| Command | Effect | Cost |
|---------|--------|------|
| `npm run dev` | Starts server only | Free |
| `npm run typecheck` | TypeScript type-check (no emit) | Free |
| `npm run backfill -- --limit 10` | Parses 10 invoices â€” safe for testing | ~$0.01 |
| `npm run backfill` | Parses all historic invoices | ~$5â€“10 |
| `npm run pipeline` | Ingest new + generate insights (no bulk parsing) | Low |
| `POST /api/v1/widgets/generate` | Insights for one fleet (no PDF parsing) | Low |

### End-to-end test run

```bash
# Parse 10 invoices to exercise the full pipeline
npm run backfill -- --limit 10

# Inspect results in Prisma Studio
npm run db:studio   # â†’ localhost:5555, check parsed_invoices table

# Generate insights for a fleet that has parsed invoices
curl -X POST "localhost:4050/api/v1/widgets/generate?fleetId=<id>" \
  -H "x-api-key: <API_KEY>"

# Get embed token and view dashboard
curl -X POST "localhost:4050/api/v1/embed-token" \
  -H "x-api-key: <API_KEY>" \
  -H "Content-Type: application/json" \
  -d '{"fleetId": <id>, "ttl": 3600}'
# â†’ open http://localhost:4050/embed/dashboard?fleetId=<id>&token=<token>
```

---

## Deployment

```bash
# Full Docker stack (local)
docker compose up -d
docker compose logs -f insights

# Production
docker compose -f docker-compose.yml up -d
```

Multi-stage Dockerfile: builder (node:22-alpine, compiles TS) â†’ runtime (prod deps only, ~200MB).
Container: port 4050, restarts unless-stopped, waits for postgres healthcheck.

**Production Firebase auth:** When deployed, the platform generates a service account automatically.
DevOps grants that service account `Storage Object Viewer` on `serviceupios.appspot.com` â€” no
`SERVICE_ACCOUNT_JSON_BASE64` needed in prod either.

---

## Data Flow: End-to-End

```
BigQuery                   Firebase Storage
(service_requests)         (PDFs)
        â”‚                      â”‚
        â””â”€â”€â”€â”€ mainDbClient â”€â”€â”€â”€â”˜
                   â”‚
              pdfFetcher (30s timeout)
                   â”‚
              pdfParser (Gemini 2.5 Flash â†’ Pro fallback)
                   â”‚
              normalizer â†’ parsed_invoices + services + line_items
                   â”‚
              embedder â†’ invoice_embeddings (gemini-embedding-001, 3072-dim)
                   â”‚
              llmAnalyzer:
                â”œâ”€â”€ metrics queries (12 parallel)
                â”œâ”€â”€ vector retrieval (pgvector cosine)
                â”œâ”€â”€ benchmarks (window functions)
                â”œâ”€â”€ NHTSA recalls (cached API)
                â”œâ”€â”€ Gemini generates â‰¤15 candidates
                â”œâ”€â”€ Judge LLM filters candidates
                â””â”€â”€ insight_cache upsert (48h TTL)
                         â”‚
                    embed routes â†’ HTML widgets â†’ <iframe> in sa_portal
```
